{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecd348c-caa7-4081-b964-32b3d90e81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulls list of all stocks listed in the NYSE to obtain news on. There is a limit on the API on daily requests of 50 every 12 hours. Would need to upgrade to implement\n",
    "#import chardet \n",
    "\n",
    "# use the detect method to find the encoding\n",
    "# 'rb' means read in the file as binary\n",
    "#with open('NYSELIST.csv', 'rb') as file:\n",
    "#    print(chardet.detect(file.read()))\n",
    "#file_path = 'NYSELIST.csv'\n",
    "#Stocklist =  pd.read_csv(\"NYSELIST.csv\", encoding=\"Windows-1252\")\n",
    "#Stocklist.drop(columns=[' Company'])\n",
    "#print(Stocklist[\" Company\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ded2d2-5867-46fb-b9f5-cae2095e86ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#library import\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "#Variable definition \n",
    "\n",
    "current_date = datetime.now().date()\n",
    "date_30_days_ago = current_date - timedelta(days=30)\n",
    "df_main=pd.DataFrame()\n",
    "Stocklist=['Exxon','Nvidia','Intel','Tesla','Ford','Kraft Heinz']\n",
    "\n",
    "for i in Stocklist:\n",
    "    url = ('https://newsapi.org/v2/everything?'\n",
    "           f'q={i}&'\n",
    "           f'from=q{current_date}&'\n",
    "           f'to=q{date_30_days_ago}'\n",
    "           'sortBy=popularity&'\n",
    "           'apiKey=')\n",
    "    response = requests.get(url)\n",
    "    data=response.json()\n",
    "    df=pd.DataFrame(data['articles'])\n",
    "    df=df.drop(columns=['source', 'author', 'description', 'url', 'urlToImage', 'publishedAt', 'content'])\n",
    "    df.insert(0, 'Ticker', i)   \n",
    "    df_main = pd.concat([df_main, df])\n",
    "#end of for\n",
    "\n",
    "#Cleaning the data by removing non ascii characters\n",
    "pattern = re.compile(r'[^\\x00-\\x7F]+')\n",
    "def contains_non_ascii(row):\n",
    "    return any(pattern.search(str(value)) for value in row)\n",
    "df_main = df_main[~df_main.apply(contains_non_ascii, axis=1)]\n",
    "mask = df_main['title'].apply(lambda text: any(element in text for element in Stocklist))\n",
    "df_main=df_main[mask]\n",
    "df_main.to_csv('News.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa28a22e-e288-4519-8722-3112572044e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'News.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "SentimentValue=0\n",
    "\n",
    "# Define keywords for positive and negative sentiment\n",
    "\n",
    "#original arrays\n",
    "#positive_keywords = ['tops','jumps','purchase','increase','sign','giant','deal','bullish','growth', 'profit', 'success','safe','generate', 'win','won', 'gain', 'improve', 'raised', 'bought', 'buy', 'acquire','acquires', 'grew','gain','Rally', 'melt up', 'was up', 'up', 'climbed', 'Rally', 'Rallied']\n",
    "#negative_keywords = ['boasts','cancel','suspension','stall','quashed','bearish','loss', 'lost','recalls', 'decline','disaster', 'problem', 'lawsuit', 'fail', 'drop', 'trimmed', 'sell', 'sold', 'cut', 'was down', 'crash', 'decrying', 'melt down', 'broken']\n",
    "\n",
    "\n",
    "positive_keywords = ['tops','jumps','purchase','increase','sign','giant','deal','growth', 'profit', 'success','safe','generate', 'win','won', 'gain', 'improve', 'raised', 'bought', 'buy', 'acquire','acquires', 'grew','gain', 'was up', 'up', 'climbed']\n",
    "very_positive_keywords=['upgrade','bullish', 'rally', 'melt up', 'rallied']\n",
    "negative_keywords = ['boasts','cancel','suspension','stall','quashed','loss', 'lost','recalls', 'decline','disaster', 'problem', 'lawsuit', 'fail', 'drop']\n",
    "very_negative_keywords=['downgrade','bearish', 'trimmed', 'sell', 'sold', 'cut', 'was down', 'crash', 'decrying', 'melt down', 'broken']\n",
    "\n",
    "def rule_based_labeling(title):\n",
    "    title = title.lower()\n",
    "    title=title.split(\" \")\n",
    "    count_positive=0\n",
    "    count_negative=0\n",
    "    for word in title:\n",
    "        match, similarity=process.extractOne(word, positive_keywords)\n",
    "        if(similarity>=80):\n",
    "            count_positive+=1\n",
    "        match, similarity=process.extractOne(word, negative_keywords)\n",
    "        if(similarity>=80):\n",
    "            count_negative+=1            \n",
    "        match, similarity=process.extractOne(word, very_positive_keywords)\n",
    "        if(similarity>=80):\n",
    "            count_positive+=2\n",
    "        match, similarity=process.extractOne(word, very_negative_keywords)\n",
    "        if(similarity>=80):\n",
    "            count_negative+=2\n",
    "    return count_positive-count_negative\n",
    "        \n",
    "\n",
    "\n",
    "# Apply rule-based labeling\n",
    "df['sentiment'] = df['title'].apply(rule_based_labeling)\n",
    "\n",
    "output_file_path = 'news_with_sentiment.csv'\n",
    "df.to_csv(output_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
